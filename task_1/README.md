# ğŸ§ª Projeto Hands-on: Pipeline com AWS S3, Glue e Athena

Este guia apresenta os passos para construir um pipeline de dados simples utilizando serviÃ§os AWS como **S3**, **Glue** e **Athena**. O objetivo Ã© simular uma arquitetura tipo "MedalhÃ£o", movendo dados de um estado bruto (**bronze**) para uma camada tratada (**silver**), com suporte a consultas SQL e organizaÃ§Ã£o de dados particionados.
## ğŸ“‘ Ãndice

1. [PrÃ©-requisitos](#prÃ©-requisitos)
2. [Etapa 1: Armazenamento no Amazon S3](#etapa-1-armazenamento-no-amazon-s3)
3. [Etapa 2: CatalogaÃ§Ã£o com AWS Glue](#etapa-2-catalogaÃ§Ã£o-com-aws-glue)
4. [Etapa 3: Consulta com AWS Athena](#etapa-3-consulta-com-aws-athena)
5. [Etapa 4: CriaÃ§Ã£o da Database e da Tabela Silver Particionada](#etapa-4-criaÃ§Ã£o-da-database-e-da-tabela-silver-particionada)
6. [Etapa 5: AtualizaÃ§Ã£o de Metadados](#etapa-5-atualizaÃ§Ã£o-de-metadados)
7. [Resultado Esperado](#resultado-esperado)
8. [Etapa Opcional: Exemplos de Queries no Athena](#etapa-opcional-exemplos-de-queries-no-athena)
9. [ReferÃªncias Oficiais AWS](#referÃªncias-oficiais-aws)
10. [ObservaÃ§Ãµes](#observaÃ§Ãµes)

---

## âœ… PrÃ©-requisitos

Antes de iniciar, verifique se vocÃª possui:

- Credenciais AWS configuradas localmente (`~/.aws/credentials`)
- AWS CLI instalada  
  ğŸ‘‰ [Guia oficial de instalaÃ§Ã£o](https://docs.aws.amazon.com/cli/latest/userguide/install-cliv2.html)
- PermissÃµes suficientes para operar com S3, Glue e Athena
- Um arquivo `.csv` simples para teste

**ValidaÃ§Ã£o de ambiente:**

Se vocÃª utiliza mÃºltiplos perfis AWS, defina o profile e a regiÃ£o padrÃ£o antes de executar comandos:

```bash
export AWS_PROFILE=mobiis
export AWS_DEFAULT_REGION=us-east-1
```

```bash
aws s3 ls
```

VocÃª deve ver a lista de buckets disponÃ­veis na conta.

---

## ğŸ“ Etapa 1: Armazenamento no Amazon S3

### 1. Criar um novo bucket

> **Nota:** Utilize um nome de bucket Ãºnico adicionando seu identificador (por exemplo, seu nome ou e-mail) ao final. Exemplo: `mobiis-treinamento-cognitivo-seunome`.  
> Iremos detalhar a escolha do nome do bucket em uma etapa futura.

```bash
aws s3 mb s3://mobiis-treinamento-cognitivo-seunome
```

### 2. Fazer upload de um arquivo BRONZE para o bucket

```bash
aws s3 cp sample_bronze_data.csv s3://mobiis-treinamento-cognitivo/bronze/sample_bronze_data/
```

### 3. Verificar se o arquivo foi enviado corretamente

```bash
aws s3 ls s3://mobiis-treinamento-cognitivo/bronze/sample_bronze_data
```

---

## ğŸ“Š Etapa 2: CatalogaÃ§Ã£o com AWS Glue

### 4. Criar a database para a camada Bronze (caso ainda nÃ£o exista)

> **Execute este comando diretamente no console do Athena** (Query Editor), pois Ã© lÃ¡ que as databases e tabelas do Data Catalog sÃ£o criadas e gerenciadas.

```sql
CREATE DATABASE IF NOT EXISTS bronze_data;
```

### 5. Criar um Glue Crawler via Console

- **Name:** crawler-seunome
- **Fonte:** `s3://mobiis-treinamento-cognitivo/bronze/sample_bronze_data`
- **Destino:** Glue Data Catalog
- **Database:** `treinamento_db_mobiis_cog`

### 6. Executar o Crawler

ApÃ³s a execuÃ§Ã£o, verifique se a tabela `sample_bronze_data` foi criada corretamente no Glue Catalog, dentro do banco de dados `treinamento_db_mobiis_cog`.

---

## ğŸ” Etapa 3: Consulta com AWS Athena

### 7. Consultar a tabela BRONZE

```sql
SELECT * FROM "treinamento_db_mobiis_cog"."sample_bronze_data";
```

---

## ğŸ§± Etapa 4: CriaÃ§Ã£o da Database e da Tabela Silver Particionada

### 8. Criar a database para a camada Silver (caso ainda nÃ£o exista)

```sql
CREATE DATABASE IF NOT EXISTS silver_data;
```

> **Nota:** O nome `silver_data` Ã© uma sugestÃ£o para organizar as tabelas da camada Silver. VocÃª pode ajustar conforme o padrÃ£o do seu projeto.

### 9. Criar a tabela particionada no Athena (camada Silver)

```sql
CREATE EXTERNAL TABLE silver_data.sample_data_partitioned (
  id  VARCHAR(20),
  idade INT,
  ativo BOOLEAN,
  salario DOUBLE,
  data_cadastro TIMESTAMP
)
PARTITIONED BY (
  ano  VARCHAR(20),
  mes  VARCHAR(20)
)
STORED AS PARQUET
LOCATION 's3://mobiis-treinamento-cognitivo/silver/'
TBLPROPERTIES (
  'parquet.compress' = 'SNAPPY'
);
```

### 10. Inserir dados na tabela particionada Silver

```sql
INSERT INTO silver_data.sample_data_partitioned
SELECT
  CAST(id AS VARCHAR(20)),
  CAST(idade AS INT),
  CAST(ativo AS BOOLEAN),
  CAST(salario AS DOUBLE),
  CAST(data_cadastro AS TIMESTAMP),
  CAST(year(CAST(data_cadastro AS TIMESTAMP)) AS VARCHAR(20)) AS ano,
  LPAD(CAST(month(CAST(data_cadastro AS TIMESTAMP)) AS VARCHAR(20)), 2, '0') AS mes
FROM "treinamento_db_mobiis_cog"."sample_bronze_data";
```

---

## ğŸ” Etapa 5: AtualizaÃ§Ã£o de Metadados

### OpÃ§Ã£o A â€“ Usar comando MSCK no Athena

```sql
MSCK REPAIR TABLE silver_data.sample_data_partitioned;
```

### OpÃ§Ã£o B â€“ Criar novo Crawler para a camada Silver

- Fonte: `s3://mobiis-treinamento-cognitivo/silver/`
- Database: `silver_data`

---

## âœ… Resultado Esperado

Ao final do exercÃ­cio, vocÃª deverÃ¡ ter:

- 1 bucket no S3 com:
  - Pasta `/bronze/` contendo o arquivo original
  - Pasta `/silver/` com os dados transformados em Parquet particionado
- 1 Glue Crawler criado e executado com sucesso
- 2 databases visÃ­veis no Athena:
  - `bronze_data` com 1 tabela CSV mapeada
  - `silver_data` com 1 tabela Parquet, compactada e particionada
- Tabelas consultÃ¡veis no Athena com performance otimizada

---

## â­ Etapa Opcional: Exemplos de Queries no Athena

### 1. Consulta simples: visualizar os primeiros registros

```sql
SELECT * FROM silver_data.sample_data_partitioned LIMIT 10;
```

### 2. Consulta com filtro: usuÃ¡rios ativos com salÃ¡rio acima de 5000

```sql
SELECT id, idade, salario, data_cadastro
FROM silver_data.sample_data_partitioned
WHERE ativo = true AND salario > 5000
ORDER BY salario DESC
LIMIT 10;
```

### 3. Consulta avanÃ§ada: ranking de salÃ¡rios por ano usando window function

```sql
SELECT
  id,
  ano,
  mes,
  salario,
  RANK() OVER (PARTITION BY ano ORDER BY salario DESC) AS rank_salario_ano
FROM silver_data.sample_data_partitioned
ORDER BY ano, rank_salario_ano
LIMIT 20;
```

---

## ğŸ“š ReferÃªncias Oficiais AWS

- [AWS CLI â€“ Comandos S3](https://docs.aws.amazon.com/cli/latest/reference/s3/index.html)
- [AWS Glue â€“ Crawler](https://docs.aws.amazon.com/glue/latest/dg/add-crawler.html)
- [Athena â€“ PreÃ§os](https://aws.amazon.com/athena/pricing/)
- [Glue â€“ PreÃ§os](https://aws.amazon.com/glue/pricing/)
- [S3 â€“ PreÃ§os](https://aws.amazon.com/s3/pricing/)

---

## ğŸ“ ObservaÃ§Ãµes

- Para simular dados reais, utilize datasets pÃºblicos ou gere dados sintÃ©ticos com Pandas.
- Evite subir arquivos grandes em ambiente de testes â€” use amostras pequenas atÃ© o pipeline estar validado.
