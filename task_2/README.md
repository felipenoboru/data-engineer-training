# ðŸ§ª Projeto Hands-on: Pipeline com AWS S3, Glue e Athena

## ðŸ“‘ Ãndice

1. [Objetivo](#objetivo)
2. [PrÃ©-requisitos](#prÃ©-requisitos)
3. [Etapas da Atividade](#etapas-da-atividade)
   - [1. Criar o Glue Job](#1-criar-o-glue-job)
   - [2. Executar o Job](#2-executar-o-job)
   - [3. Validar Resultados](#3-validar-resultados)
   - [4. Registrar a tabela Gold no Glue Catalog](#4-registrar-a-tabela-gold-no-glue-catalog)
   - [5. Verificar e Configurar PermissÃµes no IAM](#5-verificar-e-configurar-permissÃµes-no-iam)
   - [6. VerificaÃ§Ã£o Final dos Resultados](#6-verificaÃ§Ã£o-final-dos-resultados)
4. [Boas PrÃ¡ticas](#boas-prÃ¡ticas)
5. [Extras](#extras)
6. [Resultado Esperado](#resultado-esperado)

---

## ðŸ“Œ Objetivo

Nesta atividade, vamos construir um **pipeline de dados** utilizando **AWS Glue, S3 e Athena**, realizando:

- Leitura de dados particionados via **Athena**
- TransformaÃ§Ã£o com **AWS Glue + Spark**
- Escrita em uma nova camada **Gold** no S3
- VerificaÃ§Ã£o dos resultados no **Glue Catalog**, **Athena**, e **CloudWatch Logs**

O foco Ã© praticar paralelismo e boas prÃ¡ticas de execuÃ§Ã£o distribuÃ­da com **Glue Spark Jobs**, observando custo, desempenho e organizaÃ§Ã£o de logs.

---

## âœ… PrÃ©-requisitos

- Conta AWS com permissÃµes nos serviÃ§os:
  - Glue
  - S3
  - Athena
  - CloudWatch
- Tabelas previamente criadas no Glue Catalog:
  - `bronze_data.sample_bronze_data` (camada Bronze)
  - `silver_data.sample_data_partitioned` (camada Silver)
- Bucket S3 com estrutura de pastas: `bronze/`, `silver/`, `gold/`

---

## ðŸ› ï¸ Etapas da Atividade

### 1. Criar o Glue Job

- Acesse o serviÃ§o **AWS Glue > Jobs > Criar Job**.
- Preencha os campos do formulÃ¡rio conforme abaixo:

**Job Details:**
- **Name:** `job-transform-silver-to-gold`
- **IAM Role:** Selecione uma role com as permissÃµes necessÃ¡rias para Glue, S3 e Glue Catalog.
- **Type:** Spark
- **Glue Version:** Glue 5.0
- **Language:** Python 3
- **Worker Type:** G.1X
- **Number of Workers:** 2
- **Max Concurrent Runs:** 1 (ou ajuste conforme sua necessidade)
- **Script file path:** FaÃ§a upload do script Python para um bucket S3 e informe o caminho aqui.
- **Temporary directory:** Informe um caminho temporÃ¡rio em S3, por exemplo: `s3://mobiis-treinamento-cognitivo/temp/`

**ObservaÃ§Ã£o:**  
Essas configuraÃ§Ãµes garantem que o job utilize Spark 3.5 (Glue 5.0), Python 3, e execute em paralelo com 2 workers do tipo G.1X, conforme solicitado.

Adicione o seguinte cÃ³digo ao Glue Job:

```python
import sys
import boto3
import re
from awsglue.utils import getResolvedOptions
from pyspark.context import SparkContext
from awsglue.context import GlueContext
from awsglue.job import Job
from awsglue.dynamicframe import DynamicFrame

class GlueJobRunner:
    def __init__(self, job_name):
        self.args = {'JOB_NAME': job_name}
        self.sc = SparkContext()
        self.glue_context = GlueContext(self.sc)
        self.spark = self.glue_context.spark_session
        self.job = Job(self.glue_context)
        self.job.init(job_name, self.args)
        self.s3 = boto3.resource('s3')
        self.glue_client = boto3.client('glue')

    def clean_s3_path(self, s3_uri):
        """
        Limpa todos os objetos dentro do caminho S3 especificado.
        Ex: s3://bucket/path/ -> remove todos os objetos sob 'path/'
        """
        match = re.match(r"s3://([^/]+)/(.+)", s3_uri)
        if not match:
            raise ValueError("S3 URI invÃ¡lido.")
        bucket_name, prefix = match.groups()
        bucket = self.s3.Bucket(bucket_name)
        bucket.objects.filter(Prefix=prefix).delete()

    def create_catalog_table(self, database, table_name, s3_path, columns, partitions):
        """
        Cria uma nova tabela no Glue Catalog.
        """
        self.glue_client.create_table(
            DatabaseName=database,
            TableInput={
                'Name': table_name,
                'StorageDescriptor': {
                    'Columns': columns,
                    'Location': s3_path,
                    'InputFormat': 'org.apache.hadoop.hive.ql.io.parquet.MapredParquetInputFormat',
                    'OutputFormat': 'org.apache.hadoop.hive.ql.io.parquet.MapredParquetOutputFormat',
                    'SerdeInfo': {
                        'SerializationLibrary': 'org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe',
                        'Parameters': {'serialization.format': '1'}
                    },
                    'StoredAsSubDirectories': False
                },
                'PartitionKeys': partitions,
                'TableType': 'EXTERNAL_TABLE',
                'Parameters': {
                    'classification': 'parquet',
                    'compressionType': 'snappy',
                    'typeOfData': 'file'
                }
            }
        )

    def run(self):
        # ConfiguraÃ§Ãµes
        source_db = "silver_data"
        source_table = "sample_data_partitioned"
        target_db = "gold_data"
        target_table = "sample_data_aggregated"
        target_path = "s3://mobiis-treinamento-cognitivo/gold/"

        # Limpa dados antigos no S3
        self.clean_s3_path(target_path)

        # Leitura da tabela particionada da camada Silver
        df = self.glue_context.create_dynamic_frame.from_catalog(
            database=source_db,
            table_name=source_table
        )

        # TransformaÃ§Ã£o: calcula mÃ©dia salarial por idade, ativo, ano, mÃªs
        df_transformed = df.toDF() \
            .groupBy("idade", "ativo", "ano", "mes") \
            .agg({"salario": "avg"}) \
            .withColumnRenamed("avg(salario)", "salario_medio")

        # Converte de volta para DynamicFrame
        df_transformed = DynamicFrame.fromDF(df_transformed, self.glue_context, "df_transformed")

        # Cria a tabela no Glue Catalog (caso ainda nÃ£o exista)
        try:
            self.create_catalog_table(
                database=target_db,
                table_name=target_table,
                s3_path=target_path,
                columns=[
                    {"Name": "idade", "Type": "int"},
                    {"Name": "ativo", "Type": "boolean"},
                    {"Name": "salario_medio", "Type": "double"},
                ],
                partitions=[
                    {"Name": "ano", "Type": "int"},
                    {"Name": "mes", "Type": "int"}
                ]
            )
        except self.glue_client.exceptions.AlreadyExistsException:
            pass  # Tabela jÃ¡ existe

        # Escreve os dados no S3 e atualiza o catÃ¡logo Glue
        self.glue_context.write_dynamic_frame.from_options(
            frame=df_transformed,
            connection_type="s3",
            connection_options={
                "path": target_path,
                "partitionKeys": ["ano", "mes"],
                "enableUpdateCatalog": True,
                "updateBehavior": "UPDATE_IN_DATABASE",
                "database": target_db,
                "tableName": target_table
            },
            format="parquet",
            format_options={"compression": "snappy"}
        )

        self.job.commit()


if __name__ == "__main__":
    args = getResolvedOptions(sys.argv, ['JOB_NAME'])
    job_runner = GlueJobRunner(args['JOB_NAME'])
    job_runner.run()
```

âš ï¸ Configure o job com **nÃºmero de workers > 1** para garantir paralelismo.

---

### 2. Executar o Job

- Inicie o job pelo console
- Aguarde a conclusÃ£o

---

### 3. Validar Resultados

#### âœ… Glue Catalog
- Verifique se a nova tabela foi criada ou atualizada na database da camada `gold_data`.

#### âœ… Athena
- Execute a consulta:
  ```sql
  SELECT * FROM gold_data.sample_data_partitioned LIMIT 10;
  ```

#### âœ… CloudWatch Logs
- VÃ¡ em **CloudWatch > Log groups**
- Acesse o grupo correspondente ao Glue Job
- Verifique se foram criados mÃºltiplos **log streams** (um para cada executor/worker do Spark)

---

### 4. Registrar a tabela Gold no Glue Catalog

ApÃ³s a execuÃ§Ã£o do Glue Job, Ã© necessÃ¡rio garantir que a tabela e suas partiÃ§Ãµes estejam visÃ­veis no Glue Catalog e no Athena. VocÃª pode fazer isso de duas formas:

#### OpÃ§Ã£o A â€“ Criar e executar um Glue Crawler

- Acesse o serviÃ§o **AWS Glue > Crawlers > Criar Crawler**.
- **Name:** `crawler-gold-data`
- **Fonte de dados:** S3
- **Caminho:** `s3://mobiis-treinamento-cognitivo/gold/`
- **Destino:** Glue Data Catalog
- **Database:** `gold_data`
- Execute o crawler para registrar a tabela e as partiÃ§Ãµes no Glue Catalog.

#### OpÃ§Ã£o B â€“ Atualizar partiÃ§Ãµes diretamente no Athena

Se preferir, vocÃª pode atualizar as partiÃ§Ãµes da tabela gold diretamente pelo Athena com o comando:

```sql
MSCK REPAIR TABLE gold_data.sample_data_aggregated;
```

---

### 5. Verificar e Configurar PermissÃµes no IAM

Antes de executar o Glue Job, certifique-se de que a **IAM Role** associada ao job possui as permissÃµes necessÃ¡rias para acessar o S3 e o Glue Catalog.  
Inclua a seguinte policy na role utilizada pelo Glue Job:

```json
{
    "Version": "2012-10-17",
    "Statement": [
        {
            "Sid": "S3Access",
            "Effect": "Allow",
            "Action": [
                "s3:GetObject",
                "s3:PutObject",
                "s3:DeleteObject",
                "s3:ListBucket"
            ],
            "Resource": [
                "arn:aws:s3:::mobiis-treinamento-cognitivo",
                "arn:aws:s3:::mobiis-treinamento-cognitivo/*"
            ]
        },
        {
            "Sid": "GlueCatalogAccess",
            "Effect": "Allow",
            "Action": [
                "glue:CreateTable",
                "glue:UpdateTable",
                "glue:GetTable",
                "glue:GetTables",
                "glue:DeleteTable",
                "glue:GetDatabase",
                "glue:GetDatabases",
                "glue:CreateDatabase",
                "glue:UpdateDatabase",
                "glue:DeleteDatabase"
            ],
            "Resource": "*"
        }
    ]
}
```

> **Dica:**  
> Para adicionar a policy, acesse o console IAM, selecione a role usada pelo Glue Job, clique em "Adicionar permissÃµes" e cole o JSON acima.

---

### 6. VerificaÃ§Ã£o Final dos Resultados

ApÃ³s a execuÃ§Ã£o de todas as etapas, faÃ§a as seguintes verificaÃ§Ãµes para garantir que o pipeline foi concluÃ­do com sucesso:

#### a) Verificar o conteÃºdo da camada Gold no Bucket S3

- Acesse o console do S3 e navegue atÃ© o bucket `mobiis-treinamento-cognitivo/gold/`.
- Confirme que existem arquivos Parquet organizados nas pastas de partiÃ§Ã£o (`ano=` e `mes=`).
- VocÃª tambÃ©m pode usar o comando abaixo para listar os arquivos via terminal:
  ```bash
  aws s3 ls s3://mobiis-treinamento-cognitivo/gold/ --recursive
  ```

#### b) Verificar os logs do job executado no CloudWatch

- Acesse o serviÃ§o **CloudWatch > Log groups**.
- Localize o log group correspondente ao seu Glue Job (`/aws-glue/jobs/output`).
- Verifique se hÃ¡ mÃºltiplos log streams (um para cada worker) e se nÃ£o hÃ¡ erros nos logs.

#### c) Verificar os resultados das tabelas no Glue Catalog

- Acesse o serviÃ§o **AWS Glue > Databases**.
- Confirme que a tabela `sample_data_aggregated` estÃ¡ presente na database `gold_data`.
- Verifique se as partiÃ§Ãµes foram criadas corretamente.
- No Athena, execute uma consulta para visualizar os dados:
  ```sql
  SELECT * FROM gold_data.sample_data_aggregated LIMIT 10;
  ```

Se todos esses itens estiverem corretos, seu pipeline estÃ¡ funcionando de ponta a ponta!

---

## ðŸ’¡ Boas PrÃ¡ticas

- Sempre utilize **compressÃ£o Snappy** para melhor performance e custo.
- Use **partitionKeys** consistentes (ano/mes) para consultas otimizadas.
- Evite manter logs desnecessÃ¡rios: configure **retention policy** no CloudWatch.
- Utilize **monitoramento no Cost Explorer** se for testar com grandes volumes.

---

## ðŸ“Ž Extras

- ðŸ”— [DocumentaÃ§Ã£o Glue Job](https://docs.aws.amazon.com/glue/latest/dg/glue-jobs.html)
- ðŸ”— [DocumentaÃ§Ã£o CloudWatch Logs](https://docs.aws.amazon.com/AmazonCloudWatch/latest/logs/WhatIsCloudWatchLogs.html)
- ðŸ”— [AWS Pricing - Glue](https://aws.amazon.com/glue/pricing/)
- ðŸ”— [AWS Pricing - Athena](https://aws.amazon.com/athena/pricing/)
- ðŸ”— [AWS Pricing - S3](https://aws.amazon.com/s3/pricing/)

---

## âœ… Resultado Esperado

- Nova tabela criada em `gold_data.sample_data_partitioned` no Glue Catalog.
- Dados disponÃ­veis em Athena para consulta.
- Logs no CloudWatch separados por node (log stream por executor).
- Pipeline completo com leitura, transformaÃ§Ã£o, gravaÃ§Ã£o e observabilidade.

---
