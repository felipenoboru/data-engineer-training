# üß™ Projeto Hands-on: Pipeline com AWS S3, Glue e Athena

## üìë √çndice

1. [Objetivo](#objetivo)
2. [Pr√©-requisitos](#pr√©-requisitos)
3. [Etapas da Atividade](#etapas-da-atividade)
   - [1. Criar o Glue Job](#1-criar-o-glue-job)
   - [2. Executar o Job](#2-executar-o-job)
   - [3. Validar Resultados](#3-validar-resultados)
   - [4. Registrar a tabela Gold no Glue Catalog](#4-registrar-a-tabela-gold-no-glue-catalog)
   - [5. Verificar e Configurar Permiss√µes no IAM](#5-verificar-e-configurar-permiss√µes-no-iam)
   - [6. Verifica√ß√£o Final dos Resultados](#6-verifica√ß√£o-final-dos-resultados)
4. [Boas Pr√°ticas](#boas-pr√°ticas)
5. [Extras](#extras)
6. [Resultado Esperado](#resultado-esperado)

---

## üìå Objetivo

Nesta atividade, vamos construir um **pipeline de dados** utilizando **AWS Glue, S3 e Athena**, realizando:

- Leitura de dados particionados via **Athena**
- Transforma√ß√£o com **AWS Glue + Spark**
- Escrita em uma nova camada **Gold** no S3
- Verifica√ß√£o dos resultados no **Glue Catalog**, **Athena**, e **CloudWatch Logs**

O foco √© praticar paralelismo e boas pr√°ticas de execu√ß√£o distribu√≠da com **Glue Spark Jobs**, observando custo, desempenho e organiza√ß√£o de logs.

---

## ‚úÖ Pr√©-requisitos

- Conta AWS com permiss√µes nos servi√ßos:
  - Glue
  - S3
  - Athena
  - CloudWatch
- Tabelas previamente criadas no Glue Catalog:
  - `bronze_data.sample_bronze_data` (camada Bronze)
  - `silver_data.sample_data_partitioned` (camada Silver)
- Bucket S3 com estrutura de pastas: `bronze/`, `silver/`, `gold/`

---

## üõ†Ô∏è Etapas da Atividade

### 1. Criar o Glue Job

- Acesse o servi√ßo **AWS Glue > Jobs > Criar Job**.
- Preencha os campos do formul√°rio conforme abaixo:

**Job Details:**
- **Name:** `job-transform-silver-to-gold`
- **IAM Role:** Selecione uma role com as permiss√µes necess√°rias para Glue, S3 e Glue Catalog.
- **Type:** Spark
- **Glue Version:** Glue 5.0
- **Language:** Python 3
- **Worker Type:** G.1X
- **Number of Workers:** 2
- **Max Concurrent Runs:** 1 (ou ajuste conforme sua necessidade)
- **Script file path:** Fa√ßa upload do script Python para um bucket S3 e informe o caminho aqui.
- **Temporary directory:** Informe um caminho tempor√°rio em S3, por exemplo: `s3://mobiis-treinamento-cognitivo/temp/`

**Observa√ß√£o:**  
Essas configura√ß√µes garantem que o job utilize Spark 3.5 (Glue 5.0), Python 3, e execute em paralelo com 2 workers do tipo G.1X, conforme solicitado.

Adicione o seguinte c√≥digo ao Glue Job:

```python
import sys
import boto3
import re
from awsglue.utils import getResolvedOptions
from pyspark.context import SparkContext
from awsglue.context import GlueContext
from awsglue.job import Job
from awsglue.dynamicframe import DynamicFrame

class GlueJobRunner:
    def __init__(self, job_name):
        self.args = {'JOB_NAME': job_name}
        self.sc = SparkContext()
        self.glue_context = GlueContext(self.sc)
        self.spark = self.glue_context.spark_session
        self.job = Job(self.glue_context)
        self.job.init(job_name, self.args)
        self.s3 = boto3.resource('s3')
        self.glue_client = boto3.client('glue')

    def clean_s3_path(self, s3_uri):
        """
        Limpa todos os objetos dentro do caminho S3 especificado.
        Ex: s3://bucket/path/ -> remove todos os objetos sob 'path/'
        """
        match = re.match(r"s3://([^/]+)/(.+)", s3_uri)
        if not match:
            raise ValueError("S3 URI inv√°lido.")
        bucket_name, prefix = match.groups()
        bucket = self.s3.Bucket(bucket_name)
        bucket.objects.filter(Prefix=prefix).delete()

    def create_catalog_table(self, database, table_name, s3_path, columns, partitions):
        """
        Cria uma nova tabela no Glue Catalog.
        """
        self.glue_client.create_table(
            DatabaseName=database,
            TableInput={
                'Name': table_name,
                'StorageDescriptor': {
                    'Columns': columns,
                    'Location': s3_path,
                    'InputFormat': 'org.apache.hadoop.hive.ql.io.parquet.MapredParquetInputFormat',
                    'OutputFormat': 'org.apache.hadoop.hive.ql.io.parquet.MapredParquetOutputFormat',
                    'SerdeInfo': {
                        'SerializationLibrary': 'org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe',
                        'Parameters': {'serialization.format': '1'}
                    },
                    'StoredAsSubDirectories': False
                },
                'PartitionKeys': partitions,
                'TableType': 'EXTERNAL_TABLE',
                'Parameters': {
                    'classification': 'parquet',
                    'compressionType': 'snappy',
                    'typeOfData': 'file'
                }
            }
        )

    def run(self):
        # Configura√ß√µes
        source_db = "silver_data"
        source_table = "sample_data_partitioned"
        target_db = "gold_data"
        target_table = "sample_data_aggregated"
        target_path = "s3://mobiis-treinamento-cognitivo/gold/"

        # Limpa dados antigos no S3
        self.clean_s3_path(target_path)

        # Leitura da tabela particionada da camada Silver
        df = self.glue_context.create_dynamic_frame.from_catalog(
            database=source_db,
            table_name=source_table
        )

        # Transforma√ß√£o: calcula m√©dia salarial por idade, ativo, ano, m√™s
        df_transformed = df.toDF() \
            .groupBy("idade", "ativo", "ano", "mes") \
            .agg({"salario": "avg"}) \
            .withColumnRenamed("avg(salario)", "salario_medio")

        # Converte de volta para DynamicFrame
        df_transformed = DynamicFrame.fromDF(df_transformed, self.glue_context, "df_transformed")

        # Cria a tabela no Glue Catalog (caso ainda n√£o exista)
        try:
            self.create_catalog_table(
                database=target_db,
                table_name=target_table,
                s3_path=target_path,
                columns=[
                    {"Name": "idade", "Type": "int"},
                    {"Name": "ativo", "Type": "boolean"},
                    {"Name": "salario_medio", "Type": "double"},
                ],
                partitions=[
                    {"Name": "ano", "Type": "int"},
                    {"Name": "mes", "Type": "int"}
                ]
            )
        except self.glue_client.exceptions.AlreadyExistsException:
            pass  # Tabela j√° existe

        # Escreve os dados no S3 e atualiza o cat√°logo Glue
        self.glue_context.write_dynamic_frame.from_options(
            frame=df_transformed,
            connection_type="s3",
            connection_options={
                "path": target_path,
                "partitionKeys": ["ano", "mes"],
                "enableUpdateCatalog": True,
                "updateBehavior": "UPDATE_IN_DATABASE",
                "database": target_db,
                "tableName": target_table
            },
            format="parquet",
            format_options={"compression": "snappy"}
        )

        self.job.commit()


if __name__ == "__main__":
    args = getResolvedOptions(sys.argv, ['JOB_NAME'])
    job_runner = GlueJobRunner(args['JOB_NAME'])
    job_runner.run()
```

‚ö†Ô∏è Configure o job com **n√∫mero de workers > 1** para garantir paralelismo.

---

### 2. Executar o Job

- Inicie o job pelo console
- Aguarde a conclus√£o

---

### 3. Validar Resultados

#### ‚úÖ Glue Catalog
- Verifique se a nova tabela foi criada ou atualizada na database da camada `gold_data`.

#### ‚úÖ Athena
- Execute a consulta:
  ```sql
  SELECT * FROM gold_data.sample_data_partitioned LIMIT 10;
  ```

#### ‚úÖ CloudWatch Logs
- V√° em **CloudWatch > Log groups**
- Acesse o grupo correspondente ao Glue Job
- Verifique se foram criados m√∫ltiplos **log streams** (um para cada executor/worker do Spark)

---

### 4. Registrar a tabela Gold no Glue Catalog

Ap√≥s a execu√ß√£o do Glue Job, √© necess√°rio garantir que a tabela e suas parti√ß√µes estejam vis√≠veis no Glue Catalog e no Athena. Voc√™ pode fazer isso de duas formas:

#### Op√ß√£o A ‚Äì Criar e executar um Glue Crawler

- Acesse o servi√ßo **AWS Glue > Crawlers > Criar Crawler**.
- **Name:** `crawler-gold-data`
- **Fonte de dados:** S3
- **Caminho:** `s3://mobiis-treinamento-cognitivo/gold/`
- **Destino:** Glue Data Catalog
- **Database:** `gold_data`
- Execute o crawler para registrar a tabela e as parti√ß√µes no Glue Catalog.

#### Op√ß√£o B ‚Äì Atualizar parti√ß√µes diretamente no Athena

Se preferir, voc√™ pode atualizar as parti√ß√µes da tabela gold diretamente pelo Athena com o comando:

```sql
MSCK REPAIR TABLE gold_data.sample_data_aggregated;
```

---

### 5. Verificar e Configurar Permiss√µes no IAM

Antes de executar o Glue Job, certifique-se de que a **IAM Role** associada ao job possui as permiss√µes necess√°rias para acessar o S3 e o Glue Catalog.  
Inclua a seguinte policy na role utilizada pelo Glue Job:

```json
{
    "Version": "2012-10-17",
    "Statement": [
        {
            "Sid": "S3Access",
            "Effect": "Allow",
            "Action": [
                "s3:GetObject",
                "s3:PutObject",
                "s3:DeleteObject",
                "s3:ListBucket"
            ],
            "Resource": [
                "arn:aws:s3:::mobiis-treinamento-cognitivo",
                "arn:aws:s3:::mobiis-treinamento-cognitivo/*"
            ]
        },
        {
            "Sid": "GlueCatalogAccess",
            "Effect": "Allow",
            "Action": [
                "glue:CreateTable",
                "glue:UpdateTable",
                "glue:GetTable",
                "glue:GetTables",
                "glue:DeleteTable",
                "glue:GetDatabase",
                "glue:GetDatabases",
                "glue:CreateDatabase",
                "glue:UpdateDatabase",
                "glue:DeleteDatabase"
            ],
            "Resource": "*"
        }
    ]
}
```

> **Dica:**  
> Para adicionar a policy, acesse o console IAM, selecione a role usada pelo Glue Job, clique em "Adicionar permiss√µes" e cole o JSON acima.

---

### 6. Verifica√ß√£o Final dos Resultados

Ap√≥s a execu√ß√£o de todas as etapas, fa√ßa as seguintes verifica√ß√µes para garantir que o pipeline foi conclu√≠do com sucesso:

#### a) Verificar o conte√∫do da camada Gold no Bucket S3

- Acesse o console do S3 e navegue at√© o bucket `mobiis-treinamento-cognitivo/gold/`.
- Confirme que existem arquivos Parquet organizados nas pastas de parti√ß√£o (`ano=` e `mes=`).
- Voc√™ tamb√©m pode usar o comando abaixo para listar os arquivos via terminal:
  ```bash
  aws s3 ls s3://mobiis-treinamento-cognitivo/gold/ --recursive
  ```

#### b) Verificar os logs do job executado no CloudWatch

- Acesse o servi√ßo **CloudWatch > Log groups**.
- Localize o log group correspondente ao seu Glue Job (`/aws-glue/jobs/output`).
- Verifique se h√° m√∫ltiplos log streams (um para cada worker) e se n√£o h√° erros nos logs.

#### c) Verificar os resultados das tabelas no Glue Catalog

- Acesse o servi√ßo **AWS Glue > Databases**.
- Confirme que a tabela `sample_data_aggregated` est√° presente na database `gold_data`.
- Verifique se as parti√ß√µes foram criadas corretamente.
- No Athena, execute uma consulta para visualizar os dados:
  ```sql
  SELECT * FROM gold_data.sample_data_aggregated LIMIT 10;
  ```

Se todos esses itens estiverem corretos, seu pipeline est√° funcionando de ponta a ponta!

---

## üí° Boas Pr√°ticas

- Sempre utilize **compress√£o Snappy** para melhor performance e custo.
- Use **partitionKeys** consistentes (ano/mes) para consultas otimizadas.
- Evite manter logs desnecess√°rios: configure **retention policy** no CloudWatch.
- Utilize **monitoramento no Cost Explorer** se for testar com grandes volumes.

---

## üìé Extras

- üîó [Documenta√ß√£o Glue Job](https://docs.aws.amazon.com/glue/latest/dg/glue-jobs.html)
- üîó [Documenta√ß√£o CloudWatch Logs](https://docs.aws.amazon.com/AmazonCloudWatch/latest/logs/WhatIsCloudWatchLogs.html)
- üîó [AWS Pricing - Glue](https://aws.amazon.com/glue/pricing/)
- üîó [AWS Pricing - Athena](https://aws.amazon.com/athena/pricing/)
- üîó [AWS Pricing - S3](https://aws.amazon.com/s3/pricing/)

---

## ‚úÖ Resultado Esperado

- Nova tabela criada em `gold_data.sample_data_partitioned` no Glue Catalog.
- Dados dispon√≠veis em Athena para consulta.
- Logs no CloudWatch separados por node (log stream por executor).
- Pipeline completo com leitura, transforma√ß√£o, grava√ß√£o e observabilidade.

---
